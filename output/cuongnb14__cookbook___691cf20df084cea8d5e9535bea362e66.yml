# https://github.com/jairamc/docker-spark-kafka-streaming/blob/master/docker-compose.yml

version: '2'
services:
    master:
        image: jairamc/spark-kafka-streaming
        networks:
            - lambda-back
        hostname: master
        environment:
            SPARK_HOME: /usr/local/spark
            MASTER: spark://master:7077
            SPARK_CONF_DIR: /usr/local/spark/conf
            SPARK_PUBLIC_DNS: localhost
        ports:
            - 8080:8080
            - 7077:7077
            - 6066:6066
        command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.master.Master -h master

    slave:
        image: jairamc/spark-kafka-streaming
        networks:
            - lambda-back
        hostname: worker
        depends_on:
            - master
        environment:
            SPARK_HOME: /usr/local/spark
            SPARK_CONF_DIR: /usr/local/spark/conf
            SPARK_WORKER_CORES: 2
            SPARK_WORKER_MEMORY: 1g
            SPARK_WORKER_PORT: 8881
            SPARK_WORKER_WEBUI_PORT: 8081
            SPARK_PUBLIC_DNS: localhost
        ports:
            - 8081:8081
        command: /usr/local/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://master:7077

    notebook:
        image: jairamc/spark-notebook
        networks:
            - lambda-back
        environment:
            SPARK_OPTS: '--master=spark://master:7077'
        command: jupyter notebook --allow-root --ip=0.0.0.0
        ports:
            - 8888:8888
        volumes:
            - ./notebooks:/notebooks
networks:
    lambda-back:
        external: true
